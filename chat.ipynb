{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65decd49-39b3-4acf-b78f-2bd7428fd74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Obtaining dependency information for google-generativeai from https://files.pythonhosted.org/packages/3b/2c/a82d94e8829d64e1dae2e28cfe8da6010888a8e2dcb942901d4197f73546/google_generativeai-0.5.2-py3-none-any.whl.metadata\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.2 (from google-generativeai)\n",
      "  Obtaining dependency information for google-ai-generativelanguage==0.6.2 from https://files.pythonhosted.org/packages/ef/a3/06fa48fcadf2c1f3b32f2e4950333a3bfa16a1a22d9183f64cdd0d359773/google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Obtaining dependency information for google-api-core from https://files.pythonhosted.org/packages/86/75/59a3ad90d9b4ff5b3e0537611dbe885aeb96124521c9d35aa079f1e0f2c9/google_api_core-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Obtaining dependency information for google-api-python-client from https://files.pythonhosted.org/packages/de/27/60ad979de67b96ac4bea93c86d4251f7d438754919f6222c43f18c45486c/google_api_python_client-2.126.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_api_python_client-2.126.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: protobuf in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-generativeai) (1.10.8)\n",
      "Requirement already satisfied: tqdm in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.10.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.2->google-generativeai)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/ad/41/7361075f3a31dcd05a6a38cfd807a6eecbfb6dbfe420d922cd400fc03ac1/proto_plus-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for googleapis-common-protos<2.0.dev0,>=1.56.2 from https://files.pythonhosted.org/packages/dc/a6/12a0c976140511d8bc8a16ad15793b2aef29ac927baa0786ccb7ddbb6e1c/googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Obtaining dependency information for httplib2<1.dev0,>=0.19.0 from https://files.pythonhosted.org/packages/a8/6c/d2fbdaaa5959339d53ba38e94c123e4e84b8fbc4b84beb0e70d7c1608486/httplib2-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Obtaining dependency information for google-auth-httplib2<1.0.0,>=0.2.0 from https://files.pythonhosted.org/packages/be/8a/fe34d2f3f9470a27b01c9e76226965863f153d5fbe276f83608562e49c04/google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Obtaining dependency information for uritemplate<5,>=3.0.1 from https://files.pythonhosted.org/packages/81/c0/7461b49cd25aeece13766f02ee576d1db528f1c37ce69aee300e075b485b/uritemplate-4.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.62.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/33/63/56a8c67a77947d0ebc31a03c5dea8d2c933ab3ad30019b0bafa3e50a5ef6/grpcio_status-1.62.2-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/puttaranunboonchit/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for grpcio<2.0dev,>=1.33.2 from https://files.pythonhosted.org/packages/cf/fe/6c99e20e4a7deee2590524b0922f5093f5121afb425c5bd4a78828ffafb1/grpcio-1.62.2-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_python_client-2.126.0-py2.py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.62.2-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, proto-plus, httplib2, grpcio, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.62.0\n",
      "    Uninstalling grpcio-1.62.0:\n",
      "      Successfully uninstalled grpcio-1.62.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.126.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.2 googleapis-common-protos-1.63.0 grpcio-1.62.2 grpcio-status-1.62.2 httplib2-0.22.0 proto-plus-1.23.0 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaaf74b5-cbb4-4758-8ac8-182d4430bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import re\n",
    "import json\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "td = today.strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a2e77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = \"Person A: Hey, are you free to chat about the project timeline for a bit?\\nPerson B: Sure, I have some time now. What's up?\\nPerson A: I was thinking we should solidify some deadlines for the next few phases. Do you have your calendar handy?\\nPerson B: Yeah, just a sec... Okay, I'm looking at it now.\\nPerson A: Great. So, for the research phase, do you think we can wrap that up by the end of next week?\\nPerson B: Hmm, that might be a little tight. I have a couple of other deadlines that week. Could we push it to the following Monday?\\nPerson A: That works for me. And then for the design phase, are we still aiming for a two-week turnaround?\\nPerson B: Ideally, yes. But let's see how the research phase goes and adjust if needed. We might need to add a buffer day or two.\\nPerson A: Sounds good. We can have a check-in next Friday to see where we're at and finalize the design phase deadline then.\\nPerson B: Perfect. Should I put a placeholder on the calendar for that check-in?\\nPerson A: Yes, please do! And let's add a tentative deadline for the design phase as well, just so we have a target to aim for.\\nPerson B: Done and done. Anything else we need to discuss for now?\\nPerson A: I think that covers it for now. Thanks for taking the time to chat!\\nPerson B: No problem, talk to you soon!\"\n",
    "\n",
    "progress = {'task': [],\n",
    "           'category': [],\n",
    "           'progress':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "51a2cd9b-4b24-41fa-9591-834643c2eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At the command line, only need to run once to install the package via pip:\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\"\"\"\n",
    "def parse_string(string_to_parse):\n",
    "    # Find the start and end index of the JSON part\n",
    "    start_index = string_to_parse.find('{')\n",
    "    end_index = string_to_parse.rfind('}') + 1\n",
    "\n",
    "    # Extract the JSON part from the string\n",
    "    json_string = string_to_parse[start_index:end_index]\n",
    "\n",
    "    # Remove leading and trailing whitespace and newlines\n",
    "    json_string = json_string.strip()\n",
    "\n",
    "    # Remove the initial 'json' label and surrounding newlines\n",
    "    json_string = json_string.replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "    # Split the string by commas to get key-value pairs\n",
    "    pairs = json_string.split(',')\n",
    "    \n",
    "    # Initialize an empty dictionary to store key-value pairs\n",
    "    parsed_dict = {}\n",
    "\n",
    "    # Iterate over key-value pairs and split them by colons to extract keys and values\n",
    "    for pair in pairs:\n",
    "        key, value = pair.split(':')\n",
    "        # Remove surrounding whitespace and quotes from the key and value\n",
    "        key = key.strip().strip('\"')\n",
    "        value = value.strip().strip('\"')\n",
    "        # Add the key-value pair to the dictionary\n",
    "        parsed_dict[key] = value\n",
    "    return parsed_dict\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 0,\n",
    "  \"max_output_tokens\": 100,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_NONE\"\n",
    "  },\n",
    "]\n",
    "#     try:\n",
    "#         system_instruction1 = \"Given the current task: {}. As a personal assistant, your task is to inquire about the progress on the current tasks and to gather information about any new tasks along with their deadlines. It's important to approach this with empathy and encouragement, especially if the user seems tired.\".format(str(h2))\n",
    "#     except:\n",
    "system_instruction1 = \"As a personal assistant, your task is to inquire about the progress on the current tasks and to gather information about any new tasks along with their deadlines. It's important to approach this with empathy and encouragement, especially if the user seems tired.\"\n",
    "system_instruction2 = \"Given that today is {}. Extract the due date of every task mentioned, and output in the json format.\".format(td)\n",
    "\n",
    "model1 = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                              generation_config=generation_config,\n",
    "                              system_instruction=system_instruction1,\n",
    "                              safety_settings=safety_settings)\n",
    "\n",
    "model2 = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                              generation_config=generation_config,\n",
    "                              system_instruction=system_instruction2,\n",
    "                              safety_settings=safety_settings)\n",
    "\n",
    "convo1 = model1.start_chat(history=[])\n",
    "convo2 = model2.start_chat(history=[])\n",
    "\n",
    "def gemini(input_text):\n",
    "    \n",
    "\n",
    "    \n",
    "    #conversation\n",
    "    response1 = convo1.send_message(input_text)\n",
    "    print(response1.text)\n",
    "    \n",
    "    response2 = model2.generate_content(input_text)\n",
    "#     progress.update(parse_string(response2.text))\n",
    "    \n",
    "#     return progress\n",
    "    print(response2.text)\n",
    "\n",
    "# print(convo.last.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2eb59cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! How are you doing today?  Just checking in to see how things are going with your current tasks and if there's anything new on your plate.  No worries if you're feeling a bit overwhelmed, we can figure things out together.  ðŸ˜Š \n",
      "\n",
      "```json\n",
      "{\n",
      "  \"due_dates\": []\n",
      "}\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "progress = gemini('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3e310a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m progress \u001b[38;5;241m=\u001b[39m gemini(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI have assignment that dues in two days, and another exam on the same day\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[233], line 90\u001b[0m, in \u001b[0;36mgemini\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgemini\u001b[39m(input_text):\n\u001b[1;32m     86\u001b[0m     \n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m     \n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m#conversation\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     response1 \u001b[38;5;241m=\u001b[39m convo1\u001b[38;5;241m.\u001b[39msend_message(input_text)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response1\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     93\u001b[0m     response2 \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mgenerate_content(input_text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/generativeai/generative_models.py:474\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt chat with `candidate_count > 1`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 474\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    475\u001b[0m     contents\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    476\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    477\u001b[0m     safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m    478\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    479\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools_lib,\n\u001b[1;32m    480\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    481\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/generativeai/generative_models.py:262\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m    263\u001b[0m             request,\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[1;32m    265\u001b[0m         )\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:791\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    792\u001b[0m     request,\n\u001b[1;32m    793\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    795\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    796\u001b[0m )\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "progress = gemini('I have assignment that dues in two days, and another exam on the same day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7cb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
